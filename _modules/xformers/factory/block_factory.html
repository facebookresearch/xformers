


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>xformers.factory.block_factory | xFormers 0.0.1 documentation</title>
  
  <script src="../../../_static/js/ga.js"></script>
  <script src="../../../_static/js/redirect.js"></script>
  
  <link rel="shortcut icon" href="../../../_static/images/favicon.png" />
  
  
  <link rel="canonical" href="https://fairinternal.github.io/xformers_modules/xformers/factory/block_factory.html" />
  
  <meta property="og:title" content="xformers.factory.block_factory | xFormers 0.0.1 documentation">
  <meta name="description" content="API docs for xFormers. xFormers is a PyTorch extension library for composable and optimized Transformer blocks.">
  <meta property="og:description" content="API docs for xFormers. xFormers is a PyTorch extension library for composable and optimized Transformer blocks.">
  <!--<meta property="og:image" content="https://mmf.sh/img/logo.png">-->
  <!--<meta property="twitter:image" content="https://mmf.sh/img/logo.png">-->
  <meta name="twitter:image:alt" content="Image for xFormers">
  <meta name="twitter:card" content="summary_large_image">
  

  
  
  

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/css/customize.css" type="text/css" />
  <link rel="index" title="Index" href="../../../genindex.html" />
  <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://github.com/facebookresearch/xformers"><img src="_static/logo.png"
          style="padding-right: 90px;" width="280px" height="53px"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/facebookresearch/xformers"> xFormers Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p><span class="caption-text">Index</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../what_is_xformers.html">What is xFormers?</a></li>
</ul>
<p><span class="caption-text">Components Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../components/index.html">API Reference</a></li>
</ul>
<p><span class="caption-text">Factory</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../factory/index.html">Factory</a></li>
</ul>
<p><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/index.html">Tutorials</a></li>
</ul>
<p><span class="caption-text">Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../triton/index.html">Triton components reference</a></li>
</ul>
<p><span class="caption-text">Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tools/index.html">Tools</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>xformers.factory.block_factory</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">

        
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <h1>Source code for xformers.factory.block_factory</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the BSD license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>


<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">asdict</span><span class="p">,</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">from</span> <span class="nn">xformers.components</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LayerNormStyle</span><span class="p">,</span>
    <span class="n">PostNorm</span><span class="p">,</span>
    <span class="n">PreNorm</span><span class="p">,</span>
    <span class="n">Residual</span><span class="p">,</span>
    <span class="n">build_multi_head_attention</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">xformers.components.feedforward</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">FEEDFORWARD_REGISTRY</span><span class="p">,</span>
    <span class="n">FeedforwardConfig</span><span class="p">,</span>
    <span class="n">build_feedforward</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">xformers.components.positional_embedding</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">POSITION_EMBEDDING_REGISTRY</span><span class="p">,</span>
    <span class="n">PositionEmbeddingConfig</span><span class="p">,</span>
    <span class="n">build_positional_embedding</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">xformers.utils</span> <span class="kn">import</span> <span class="n">generate_matching_config</span>


<div class="viewcode-block" id="LayerPositionBitmask"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.LayerPositionBitmask">[docs]</a><span class="k">class</span> <span class="nc">LayerPositionBitmask</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
    <span class="n">First</span> <span class="o">=</span> <span class="mb">0b01</span>
    <span class="n">Last</span> <span class="o">=</span> <span class="mb">0b10</span>
    <span class="n">Default</span> <span class="o">=</span> <span class="mb">0b11</span></div>


<div class="viewcode-block" id="LayerPosition"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.LayerPosition">[docs]</a><span class="k">class</span> <span class="nc">LayerPosition</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot; Bitmask to mark this layer as first, last, nothing or both&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bitmask</span> <span class="o">=</span> <span class="n">LayerPositionBitmask</span><span class="o">.</span><span class="n">Default</span>

<div class="viewcode-block" id="LayerPosition.is_first"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.LayerPosition.is_first">[docs]</a>    <span class="k">def</span> <span class="nf">is_first</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bitmask</span> <span class="o">&amp;</span> <span class="n">LayerPositionBitmask</span><span class="o">.</span><span class="n">First</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayerPosition.is_last"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.LayerPosition.is_last">[docs]</a>    <span class="k">def</span> <span class="nf">is_last</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bitmask</span> <span class="o">&amp;</span> <span class="n">LayerPositionBitmask</span><span class="o">.</span><span class="n">Last</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayerPosition.mark_not_first"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.LayerPosition.mark_not_first">[docs]</a>    <span class="k">def</span> <span class="nf">mark_not_first</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bitmask</span> <span class="o">&amp;=</span> <span class="o">~</span><span class="n">LayerPositionBitmask</span><span class="o">.</span><span class="n">First</span></div>

<div class="viewcode-block" id="LayerPosition.mark_not_last"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.LayerPosition.mark_not_last">[docs]</a>    <span class="k">def</span> <span class="nf">mark_not_last</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bitmask</span> <span class="o">&amp;=</span> <span class="o">~</span><span class="n">LayerPositionBitmask</span><span class="o">.</span><span class="n">Last</span></div></div>


<div class="viewcode-block" id="BlockType"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.BlockType">[docs]</a><span class="k">class</span> <span class="nc">BlockType</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
    <span class="n">Encoder</span> <span class="o">=</span> <span class="s2">&quot;encoder&quot;</span>
    <span class="n">Decoder</span> <span class="o">=</span> <span class="s2">&quot;decoder&quot;</span></div>


<span class="k">def</span> <span class="nf">_get_ln_factory</span><span class="p">(</span>
    <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">layer_norm_style</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LayerNormStyle</span><span class="p">],</span>
    <span class="n">residual</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">use_triton</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
    <span class="k">def</span> <span class="nf">get_layer_wrapper</span><span class="p">(</span>
        <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sublayer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">layer_norm_style</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LayerNormStyle</span><span class="p">],</span>
        <span class="n">residual</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">residual</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="n">Residual</span><span class="p">(</span><span class="n">PreNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">sublayer</span><span class="p">,</span> <span class="n">use_triton</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">layer_norm_style</span> <span class="o">==</span> <span class="n">LayerNormStyle</span><span class="o">.</span><span class="n">Pre</span>
                <span class="k">else</span> <span class="n">PostNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">Residual</span><span class="p">(</span><span class="n">sublayer</span><span class="p">),</span> <span class="n">use_triton</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">PreNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">sublayer</span><span class="p">,</span> <span class="n">use_triton</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">layer_norm_style</span> <span class="o">==</span> <span class="n">LayerNormStyle</span><span class="o">.</span><span class="n">Pre</span>
            <span class="k">else</span> <span class="n">PostNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">sublayer</span><span class="p">,</span> <span class="n">use_triton</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">ln_factory</span><span class="p">(</span><span class="n">sublayer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">get_layer_wrapper</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">sublayer</span><span class="p">,</span> <span class="n">layer_norm_style</span><span class="p">,</span> <span class="n">residual</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ln_factory</span>


<div class="viewcode-block" id="xFormerBlockConfig"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.xFormerBlockConfig">[docs]</a><span class="nd">@dataclass</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># handle constructors explicitly to force type changes</span>
<span class="k">class</span> <span class="nc">xFormerBlockConfig</span><span class="p">:</span>
    <span class="n">dim_model</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">feedforward_config</span><span class="p">:</span> <span class="n">FeedforwardConfig</span>
    <span class="n">position_encoding_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PositionEmbeddingConfig</span><span class="p">]</span>
    <span class="n">block_type</span><span class="p">:</span> <span class="n">BlockType</span>
    <span class="n">layer_norm_style</span><span class="p">:</span> <span class="n">LayerNormStyle</span>
    <span class="n">layer_position</span><span class="p">:</span> <span class="n">LayerPosition</span>
    <span class="n">use_triton</span><span class="p">:</span> <span class="nb">bool</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dim_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">feedforward_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">position_encoding_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="n">block_type</span><span class="p">:</span> <span class="n">BlockType</span><span class="p">,</span>
        <span class="n">layer_norm_style</span><span class="p">:</span> <span class="n">LayerNormStyle</span> <span class="o">=</span> <span class="n">LayerNormStyle</span><span class="p">(</span><span class="s2">&quot;post&quot;</span><span class="p">),</span>
        <span class="n">use_triton</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_model</span> <span class="o">=</span> <span class="n">dim_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block_type</span> <span class="o">=</span> <span class="n">block_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_style</span> <span class="o">=</span> <span class="n">layer_norm_style</span>

        <span class="c1"># Fill in possible gaps in the config for subparts of the block</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feedforward_config</span> <span class="o">=</span> <span class="n">generate_matching_config</span><span class="p">(</span>
            <span class="n">feedforward_config</span><span class="p">,</span>
            <span class="n">FEEDFORWARD_REGISTRY</span><span class="p">[</span><span class="n">feedforward_config</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">position_encoding_config</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">generate_matching_config</span><span class="p">(</span>
                <span class="n">position_encoding_config</span><span class="p">,</span>
                <span class="n">POSITION_EMBEDDING_REGISTRY</span><span class="p">[</span><span class="n">position_encoding_config</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">position_encoding_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="c1"># Default is that this layer is the only one, so both first and last</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_position</span> <span class="o">=</span> <span class="n">LayerPosition</span><span class="p">()</span></div>


<div class="viewcode-block" id="xFormerEncoderConfig"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.xFormerEncoderConfig">[docs]</a><span class="nd">@dataclass</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">xFormerEncoderConfig</span><span class="p">(</span><span class="n">xFormerBlockConfig</span><span class="p">):</span>
    <span class="n">multi_head_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dim_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">feedforward_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">multi_head_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">position_encoding_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">layer_norm_style</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;post&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">dim_model</span><span class="o">=</span><span class="n">dim_model</span><span class="p">,</span>
            <span class="n">feedforward_config</span><span class="o">=</span><span class="n">feedforward_config</span><span class="p">,</span>
            <span class="n">position_encoding_config</span><span class="o">=</span><span class="n">position_encoding_config</span><span class="p">,</span>
            <span class="n">layer_norm_style</span><span class="o">=</span><span class="n">LayerNormStyle</span><span class="p">(</span><span class="n">layer_norm_style</span><span class="p">),</span>
            <span class="n">block_type</span><span class="o">=</span><span class="n">BlockType</span><span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">multi_head_config</span> <span class="o">=</span> <span class="n">multi_head_config</span></div>


<div class="viewcode-block" id="xFormerDecoderConfig"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.xFormerDecoderConfig">[docs]</a><span class="nd">@dataclass</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">xFormerDecoderConfig</span><span class="p">(</span><span class="n">xFormerBlockConfig</span><span class="p">):</span>
    <span class="n">multi_head_config_masked</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>  <span class="c1"># prior to encoder output</span>
    <span class="n">multi_head_config_cross</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>  <span class="c1"># cross attention, takes encoder output</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dim_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">feedforward_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">multi_head_config_masked</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">multi_head_config_cross</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">position_encoding_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">layer_norm_style</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;post&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">dim_model</span><span class="o">=</span><span class="n">dim_model</span><span class="p">,</span>
            <span class="n">feedforward_config</span><span class="o">=</span><span class="n">feedforward_config</span><span class="p">,</span>
            <span class="n">position_encoding_config</span><span class="o">=</span><span class="n">position_encoding_config</span><span class="p">,</span>
            <span class="n">layer_norm_style</span><span class="o">=</span><span class="n">LayerNormStyle</span><span class="p">(</span><span class="n">layer_norm_style</span><span class="p">),</span>
            <span class="n">block_type</span><span class="o">=</span><span class="n">BlockType</span><span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">multi_head_config_masked</span> <span class="o">=</span> <span class="n">multi_head_config_masked</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multi_head_config_cross</span> <span class="o">=</span> <span class="n">multi_head_config_cross</span></div>


<div class="viewcode-block" id="xFormerEncoderBlock"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.xFormerEncoderBlock">[docs]</a><span class="k">class</span> <span class="nc">xFormerEncoderBlock</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot; A vanilla Transformer Encoder block &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">xFormerEncoderConfig</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reversible_f</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reversible_g</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_style</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">layer_norm_style</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_model</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">dim_model</span>

        <span class="c1"># If this layer is the first one, and a pose encoding has been requested</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pose_encoding</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">build_positional_embedding</span><span class="p">(</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">position_encoding_config</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">position_encoding_config</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">layer_position</span><span class="o">.</span><span class="n">is_first</span><span class="p">()</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="c1"># mini helper, builds a LayerNorm with the right Pre/Post config, residuals, and the right dimensions</span>
        <span class="n">ln_factory</span> <span class="o">=</span> <span class="n">_get_ln_factory</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">layer_norm_style</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">build_multi_head_attention</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">multi_head_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span> <span class="o">=</span> <span class="n">build_feedforward</span><span class="p">(</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">feedforward_config</span><span class="p">))</span>

        <span class="c1"># Wrappers handle the different layer norm styles (pre- and post-) and the residual path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wrap_att</span> <span class="o">=</span> <span class="n">ln_factory</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wrap_ff</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Residual</span><span class="p">,</span> <span class="n">PostNorm</span><span class="p">]</span> <span class="o">=</span> <span class="n">ln_factory</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">config</span><span class="o">.</span><span class="n">layer_norm_style</span> <span class="o">==</span> <span class="n">LayerNormStyle</span><span class="o">.</span><span class="n">Pre</span>
            <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">layer_position</span><span class="o">.</span><span class="n">is_last</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wrap_ff</span> <span class="o">=</span> <span class="n">PostNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrap_ff</span><span class="p">)</span>

<div class="viewcode-block" id="xFormerEncoderBlock.from_config"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.xFormerEncoderBlock.from_config">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">xFormerEncoderConfig</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="p">)</span></div>

<div class="viewcode-block" id="xFormerEncoderBlock.get_reversible_layer"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.xFormerEncoderBlock.get_reversible_layer">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_reversible_layer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]:</span>
        <span class="n">ln_factory</span> <span class="o">=</span> <span class="n">_get_ln_factory</span><span class="p">(</span>
            <span class="n">config</span><span class="o">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">layer_norm_style</span><span class="p">,</span> <span class="n">residual</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">mha</span> <span class="o">=</span> <span class="n">build_multi_head_attention</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">multi_head_config</span><span class="p">)</span>
        <span class="n">feedforward</span> <span class="o">=</span> <span class="n">build_feedforward</span><span class="p">(</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">feedforward_config</span><span class="p">))</span>

        <span class="n">reversible_f</span> <span class="o">=</span> <span class="n">ln_factory</span><span class="p">(</span><span class="n">mha</span><span class="p">)</span>
        <span class="n">reversible_g</span> <span class="o">=</span> <span class="n">ln_factory</span><span class="p">(</span><span class="n">feedforward</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reversible_f</span><span class="p">,</span> <span class="n">reversible_g</span></div>

<div class="viewcode-block" id="xFormerEncoderBlock.forward"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.xFormerEncoderBlock.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">att_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pose_encoding</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pose_encoding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Handle the optional input masking, differs on Q, K, V</span>
        <span class="k">if</span> <span class="n">input_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">q</span> <span class="o">=</span> <span class="n">x</span>
            <span class="n">k</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">input_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">k</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span>

        <span class="c1"># Pre/Post norms and residual paths are already handled</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrap_att</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">att_mask</span><span class="o">=</span><span class="n">att_mask</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrap_ff</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span></div></div>


<div class="viewcode-block" id="xFormerDecoderBlock"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.xFormerDecoderBlock">[docs]</a><span class="k">class</span> <span class="nc">xFormerDecoderBlock</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;A vanilla Transformer Decoder block</span>

<span class="sd">    ... note: this implementation is not (yet ?) reversible&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">xFormerDecoderConfig</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># If this layer is the first one, and a pose encoding as been requested</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pose_encoding</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">build_positional_embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">position_encoding_config</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">position_encoding_config</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">layer_position</span><span class="o">.</span><span class="n">is_first</span><span class="p">()</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="c1"># mini helper, builds a LayerNorm with the right Pre/Post config and the right dimensions</span>
        <span class="n">ln_factory</span> <span class="o">=</span> <span class="n">_get_ln_factory</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">layer_norm_style</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">build_multi_head_attention</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">multi_head_config_masked</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cross_mha</span> <span class="o">=</span> <span class="n">build_multi_head_attention</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">multi_head_config_cross</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span> <span class="o">=</span> <span class="n">build_feedforward</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">feedforward_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">wrap_att</span> <span class="o">=</span> <span class="n">ln_factory</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wrap_cross</span> <span class="o">=</span> <span class="n">ln_factory</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cross_mha</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wrap_ff</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Residual</span><span class="p">,</span> <span class="n">PostNorm</span><span class="p">]</span> <span class="o">=</span> <span class="n">ln_factory</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">config</span><span class="o">.</span><span class="n">layer_norm_style</span> <span class="o">==</span> <span class="n">LayerNormStyle</span><span class="o">.</span><span class="n">Pre</span>
            <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">layer_position</span><span class="o">.</span><span class="n">is_last</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wrap_ff</span> <span class="o">=</span> <span class="n">PostNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrap_ff</span><span class="p">)</span>

<div class="viewcode-block" id="xFormerDecoderBlock.from_config"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.xFormerDecoderBlock.from_config">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">xFormerDecoderConfig</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="p">)</span></div>

<div class="viewcode-block" id="xFormerDecoderBlock.forward"><a class="viewcode-back" href="../../../factory/block.html#xformers.factory.block_factory.xFormerDecoderBlock.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">memory</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">encoder_att_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">decoder_att_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pose_encoding</span><span class="p">:</span>
            <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pose_encoding</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

        <span class="c1"># Handle the optional input masking, differs on Q, K, V</span>
        <span class="k">if</span> <span class="n">input_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">target_q</span> <span class="o">=</span> <span class="n">target</span>
            <span class="n">target_k</span> <span class="o">=</span> <span class="n">target</span> <span class="o">*</span> <span class="n">input_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">target_v</span> <span class="o">=</span> <span class="n">target_k</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">target_q</span><span class="p">,</span> <span class="n">target_k</span><span class="p">,</span> <span class="n">target_v</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">target</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrap_att</span><span class="p">([</span><span class="n">target_q</span><span class="p">,</span> <span class="n">target_k</span><span class="p">,</span> <span class="n">target_v</span><span class="p">],</span> <span class="n">att_mask</span><span class="o">=</span><span class="n">decoder_att_mask</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrap_cross</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory</span><span class="p">],</span> <span class="n">att_mask</span><span class="o">=</span><span class="n">encoder_att_mask</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wrap_ff</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span></div></div>
</pre></div>

              </article>
              
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Facebook AI Research.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <!-- <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div> -->
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../../../"
    src="../../../_static/documentation_options.js"></script>
  <script src="../../../_static/jquery.js"></script>
  <script src="../../../_static/underscore.js"></script>
  <script src="../../../_static/doctools.js"></script>
  <script src="../../../_static/language_data.js"></script>
  

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->


  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://github.com/facebookresearch/xformers" class="footer-logo"></a>
      </div>
      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://github.com/facebookresearch/xformers">fairscale</a></li>
            <li><a href="https://github.com/facebookresearch/xformers/blob/master/README.md">Get Started</a></li>
            <li><a href="https://github.com/facebookresearch/xformers/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="">Resources</a></li>
            <li><a href="https://github.com/facebookresearch/xformers">Docs</a></li>
            <li><a href="https://github.com/facebookresearch/xformers/issues" target="_blank">Github Issues</a></li>
          </ul>
        </div>
      </div>
    </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebooks Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://github.com/facebookresearch/xformers" aria-label="fairscale"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/facebookresearch/xformers/blob/master/README.md">Get Started</a>
          </li>

          <li>
            <a href="https://github.com/facebookresearch/xformers">Docs</a>
          </li>

          <li>
            <a href="https://github.com/facebookresearch/xformers">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>