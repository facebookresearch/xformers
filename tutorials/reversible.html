


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Using the Reversible block | xFormers 0.0.29 documentation</title>
  
  <script src="../_static/js/ga.js"></script>
  <script src="../_static/js/redirect.js"></script>
  
  <link rel="shortcut icon" href="../_static/images/favicon.png" />
  
  
  <link rel="canonical" href="https://facebookresearch.github.io/xformerstutorials/reversible.html" />
  
  <meta property="og:title" content="Using the Reversible block | xFormers 0.0.29 documentation">
  <meta name="description" content="API docs for xFormers. xFormers is a PyTorch extension library for composable and optimized Transformer blocks.">
  <meta property="og:description" content="API docs for xFormers. xFormers is a PyTorch extension library for composable and optimized Transformer blocks.">
  <!--<meta property="og:image" content="https://mmf.sh/img/logo.png">-->
  <!--<meta property="twitter:image" content="https://mmf.sh/img/logo.png">-->
  <meta name="twitter:image:alt" content="Image for xFormers">
  <meta name="twitter:card" content="summary_large_image">
  

  
  
  

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/css/customize.css" type="text/css" />
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="Custom parts reference" href="../custom_parts/index.html" />
  <link rel="prev" title="I’m only interested in testing out the attention mechanisms that are hosted here" href="use_attention.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://github.com/facebookresearch/xformers"><img
          src="../_static/logo.png" style="padding-right: 90px;" width="280px" height="53px"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/facebookresearch/xformers"> xFormers Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">Index</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../what_is_xformers.html">What is xFormers?</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Components Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../components/index.html">API Reference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials and examples</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Some custom parts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../custom_parts/index.html">Custom parts reference</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">Tutorials</a> &gt;</li>
        
      <li>Using the Reversible block</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/reversible.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">

        
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <section id="using-the-reversible-block">
<h1>Using the Reversible block<a class="headerlink" href="#using-the-reversible-block" title="Permalink to this heading">¶</a></h1>
<section id="intro">
<h2>Intro<a class="headerlink" href="#intro" title="Permalink to this heading">¶</a></h2>
<p>This block applies to residual paths, and was first proposed by Gomez et al (<a class="footnote-reference brackets" href="#id6" id="id1">1</a>).
Its application in the Transformer (<a class="footnote-reference brackets" href="#id8" id="id2">3</a>) context was first proposed in the <cite>Reformer</cite> (<a class="footnote-reference brackets" href="#id7" id="id3">2</a>) paper,
and is largely unrelated to the other proposals from this paper (LSH and chunked MLP processing).</p>
<p>We use and very lightly adapt the implementation by Robin <a class="reference external" href="https://github.com/RobinBruegger/RevTorch/blob/master/revtorch/revtorch.py">Bruegger</a> and some blocks from <a class="reference external" href="https://github.com/lucidrains/reformer-pytorch/blob/master/reformer_pytorch/reversible.py">LucidRains</a>.</p>
<p>A reversible layer requires two inputs (x1, x2) and produces two outputs (y1, y2)
via two functions F and G, following the relations</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y1</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">F</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">+</span> <span class="n">G</span><span class="p">(</span><span class="n">y1</span><span class="p">)</span>
</pre></div>
</div>
<p>In turn, this means that (x1, x2) can be recovered from (y1, y2) (see <a class="footnote-reference brackets" href="#id6" id="id4">1</a> for details)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="n">y2</span> <span class="o">-</span> <span class="n">G</span><span class="p">(</span><span class="n">y1</span><span class="p">)</span>  <span class="c1"># Note that another FW-like pass is needed</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">y1</span> <span class="o">-</span> <span class="n">F</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
</pre></div>
</div>
<p>The effect is comparable to activation checkpointing, in that it opens up for a tradeoff in between GPU memory
and compute. One benefit is that no extra wrap is needed, all the residual paths can be naturally checkpointed.
In a distributed setting, freeing up GPU memory can help using less GPUs, and the saved communication cost can more than make up for the extra compute.</p>
<p>Moreover, if your model is made of a stack of reversible blocks, then the memory requirement does not increase with the number of blocks.</p>
</section>
<section id="transformer">
<h2>Transformer<a class="headerlink" href="#transformer" title="Permalink to this heading">¶</a></h2>
<p>Considering the multi-head attention and feedforward blocks (including the residual paths), one can set F as MHA (+ layer norm) and G as Feedforward (+ layer norm) and get to something very close (but not exactly the same) to the original Transformer formulation from [Vaswani et al.][3], as follows</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y1</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">MHA</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">+</span> <span class="n">Feedforward</span><span class="p">(</span><span class="n">y1</span><span class="p">)</span>
</pre></div>
</div>
<p>A difference is that the residual path in the Feedforward deals with the original input, and not the MHA output,
but in practice if <cite>dim(x1) == dim(x2) == dim(model)</cite>, the accuracy should not be affected, as verified in <a class="footnote-reference brackets" href="#id7" id="id5">2</a> and in xFormers.</p>
</section>
<section id="in-practice">
<h2>In practice<a class="headerlink" href="#in-practice" title="Permalink to this heading">¶</a></h2>
<p>This repository exposes two main helpers in <cite>xformers.components.reversible</cite>: ReversibleBlock and ReversibleSequence. <cite>ReversibleBlock</cite> will take <cite>f</cite> and <cite>g</cite> as defined above, and <cite>ReversibleSequence</cite> can combine them sequentially, similarly to <cite>torch.nn.ModuleList</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReversibleBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">g</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">f_args</span><span class="o">=</span><span class="p">{},</span> <span class="n">g_args</span><span class="o">=</span><span class="p">{}):</span>
        <span class="o">...</span>


<span class="k">class</span> <span class="nc">ReversibleSequence</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">blocks</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">arg_route</span><span class="o">=</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        arg_route: whether to route the kwargs to f and g</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>Reversible layers are also exposed as a boolean option in when building complete xFormers (which is optional), as defined in <cite>xformers.factory.model_factory</cite>. Please note that the reversible layer is not yet compatible with the use of multiple forward passes and DDP.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">xFormerStackConfig</span><span class="p">:</span>
    <span class="n">block_config</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">xFormerEncoderConfig</span><span class="p">,</span> <span class="n">xFormerDecoderConfig</span><span class="p">]</span>
    <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">reversible</span><span class="p">:</span> <span class="nb">bool</span>  <span class="c1"># the sequence of layers becomes reversible</span>
</pre></div>
</div>
<dl class="footnote brackets">
<dt class="label" id="id6"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>Gomez, A. N., Ren, M., Urtasun, R., &amp; Grosse, R. B. (2017).
The reversible residual network: Backpropagation without storing activations.</p>
</dd>
<dt class="label" id="id7"><span class="brackets">2</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id5">2</a>)</span></dt>
<dd><p>Kitaev, N., Kaiser, Ł., &amp; Levskaya, A. (2020).
Reformer: The Efficient Transformer.</p>
</dd>
<dt class="label" id="id8"><span class="brackets"><a class="fn-backref" href="#id2">3</a></span></dt>
<dd><p>Vaswani et al.,
Attention is all you need, 2017</p>
</dd>
</dl>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../custom_parts/index.html" class="btn btn-neutral float-right" title="Custom parts reference" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="use_attention.html" class="btn btn-neutral" title="I’m only interested in testing out the attention mechanisms that are hosted here" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright Copyright © 2021 Meta Platforms, Inc.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <!-- <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Using the Reversible block</a><ul>
<li><a class="reference internal" href="#intro">Intro</a></li>
<li><a class="reference internal" href="#transformer">Transformer</a></li>
<li><a class="reference internal" href="#in-practice">In practice</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div> -->
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../"
    src="../_static/documentation_options.js"></script>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/jquery.js"></script>
  <script src="../_static/underscore.js"></script>
  <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
  <script src="../_static/doctools.js"></script>
  

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->


  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://github.com/facebookresearch/xformers" class="footer-logo"></a>
      </div>
      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://github.com/facebookresearch/xformers">fairscale</a></li>
            <li><a href="https://github.com/facebookresearch/xformers/blob/master/README.md">Get Started</a></li>
            <li><a href="https://github.com/facebookresearch/xformers/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="">Resources</a></li>
            <li><a href="https://github.com/facebookresearch/xformers">Docs</a></li>
            <li><a href="https://github.com/facebookresearch/xformers/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://opensource.facebook.com/legal/terms">Terms of Use</a></li>
            <li><a href="https://opensource.facebook.com/legal/privacy">Privacy Policy</a></li>
          </ul>
        </div>
      </div>
    </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://github.com/facebookresearch/xformers" aria-label="fairscale"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/facebookresearch/xformers/blob/master/README.md">Get Started</a>
          </li>

          <li>
            <a href="https://github.com/facebookresearch/xformers">Docs</a>
          </li>

          <li>
            <a href="https://github.com/facebookresearch/xformers">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>